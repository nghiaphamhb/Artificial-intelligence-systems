{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "65imDUG-jV3y",
        "N8gx4qSa8wup"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scXE7i0cVTPm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision tree:"
      ],
      "metadata": {
        "id": "65imDUG-jV3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "class DecisionTree:\n",
        "    class _Node:\n",
        "        def __init__(\n",
        "            self,\n",
        "            is_leaf=False,\n",
        "            value=None,\n",
        "            feature_index=None,\n",
        "            threshold=None,\n",
        "            left=None,\n",
        "            right=None\n",
        "        ):\n",
        "            self.is_leaf = is_leaf\n",
        "            self.value = value\n",
        "            self.feature_index = feature_index\n",
        "            self.threshold = threshold\n",
        "            self.left = left\n",
        "            self.right = right\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        classification: bool = True,\n",
        "        max_depth: int = None,\n",
        "        min_samples_split: int = 2,\n",
        "        min_samples_leaf: int = 1,\n",
        "        criterion: str = None,\n",
        "        verbose: bool = False,\n",
        "    ):\n",
        "\n",
        "        self.classification = classification   # true -> classification; false -> regression\n",
        "        self.max_depth = max_depth             # None -> unlimited\n",
        "        self.min_samples_split = min_samples_split  # minimum sample number to continue splitting\n",
        "        self.min_samples_leaf = min_samples_leaf    # minimum sample number in each leaf\n",
        "        self.verbose = verbose\n",
        "\n",
        "        if criterion is None:\n",
        "            if classification:\n",
        "                criterion = \"gini\"\n",
        "            else:\n",
        "                criterion = \"mse\"\n",
        "        self.criterion = criterion\n",
        "\n",
        "        self.root = None\n",
        "\n",
        "    # --------- PUBLIC ---------\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        X: numpy array shape (n_samples, n_features)\n",
        "        y: numpy array shape (n_samples,)\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        self.n_classes_ = None\n",
        "        if self.classification:\n",
        "            self.n_classes_ = len(np.unique(y))\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"[FIT] Start training\")\n",
        "            print(f\"      n_samples={len(y)}, n_features={X.shape[1]}, \"\n",
        "                  f\"classification={self.classification}, criterion={self.criterion}\")\n",
        "\n",
        "        # build tree (chỉ gọi 1 lần)\n",
        "        self.root = self._build_tree(X, y, depth=0)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"[FIT] Done building tree.\")\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        preds = [self._predict_one(x, self.root) for x in X]  # predict one\n",
        "        return np.array(preds)\n",
        "\n",
        "    # --------- INTERNAL ---------\n",
        "\n",
        "    def _build_tree(self, X, y, depth):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        if self.verbose:\n",
        "            # Giảm log nếu depth quá lớn thì có thể thêm điều kiện: if depth <= 5:\n",
        "            print(f\"[NODE] depth={depth}, n_samples={n_samples}, \"\n",
        "                  f\"unique_labels={np.unique(y)}\")\n",
        "\n",
        "        # Stop condition\n",
        "        if self._should_stop(y, depth, n_samples):\n",
        "            leaf_value = self._leaf_value(y)  # take leaf's value\n",
        "            if self.verbose:\n",
        "                print(f\"  -> Leaf created at depth={depth}, value={leaf_value}\")\n",
        "            return self._Node(is_leaf=True, value=leaf_value)  # return leaf node\n",
        "\n",
        "        # Find best split\n",
        "        best_feature, best_threshold, best_gain = self._best_split(X, y)\n",
        "\n",
        "        # Cannot find best split -> leaf\n",
        "        if best_feature is None:\n",
        "            leaf_value = self._leaf_value(y)\n",
        "            if self.verbose:\n",
        "                print(f\"  -> No valid split at depth={depth}, \"\n",
        "                      f\"create leaf with value={leaf_value}\")\n",
        "            return self._Node(is_leaf=True, value=leaf_value)\n",
        "\n",
        "        # Split data\n",
        "        left_mask = X[:, best_feature] <= best_threshold\n",
        "        right_mask = ~left_mask  # right mask = X > best_threshold\n",
        "\n",
        "        X_left, y_left = X[left_mask], y[left_mask]\n",
        "        X_right, y_right = X[right_mask], y[right_mask]\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"  -> Best split: feature={best_feature}, \"\n",
        "                  f\"threshold={best_threshold}, gain={best_gain:.6f}\")\n",
        "            print(f\"     Left n={len(y_left)}, Right n={len(y_right)}\")\n",
        "\n",
        "        # Buid child (create recursion)\n",
        "        left_child = self._build_tree(X_left, y_left, depth + 1)\n",
        "        right_child = self._build_tree(X_right, y_right, depth + 1)\n",
        "\n",
        "        return self._Node(  # return internal node\n",
        "            is_leaf=False,\n",
        "            value=None,\n",
        "            feature_index=best_feature,\n",
        "            threshold=best_threshold,\n",
        "            left=left_child,\n",
        "            right=right_child\n",
        "        )\n",
        "\n",
        "    # stop condition\n",
        "    def _should_stop(self, y, depth, n_samples):\n",
        "        # 1) depth > max_depth\n",
        "        if self.max_depth is not None and depth >= self.max_depth:\n",
        "            if self.verbose:\n",
        "                print(f\"[STOP] depth={depth} reached max_depth={self.max_depth}\")\n",
        "            return True\n",
        "\n",
        "        # 2) Dont have enough samples to split\n",
        "        if n_samples < self.min_samples_split:\n",
        "            if self.verbose:\n",
        "                print(f\"[STOP] n_samples={n_samples} < min_samples_split={self.min_samples_split}\")\n",
        "            return True\n",
        "\n",
        "        # 3) (if classification) same labels in samples\n",
        "        if self.classification and len(np.unique(y)) == 1:\n",
        "            if self.verbose:\n",
        "                print(f\"[STOP] All samples have same label={y[0]}\")\n",
        "            return True\n",
        "\n",
        "        # 4) regression (not yet)\n",
        "        return False\n",
        "\n",
        "    # --------- LEAF VALUE ---------\n",
        "\n",
        "    def _leaf_value(self, y):\n",
        "        if self.classification:\n",
        "            # majority vote\n",
        "            counter = Counter(y)\n",
        "            return counter.most_common(1)[0][0]\n",
        "        else:\n",
        "            # regression: mean\n",
        "            return float(np.mean(y))\n",
        "\n",
        "    # --------- IMPURITY ---------\n",
        "\n",
        "    def _impurity(self, y):\n",
        "        if self.classification:\n",
        "            if self.criterion == \"gini\":\n",
        "                return self._gini(y)\n",
        "            elif self.criterion == \"entropy\":\n",
        "                return self._entropy(y)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown criterion {self.criterion}\")\n",
        "        else:\n",
        "            if self.criterion == \"mse\":\n",
        "                return self._mse(y)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown criterion {self.criterion}\")\n",
        "\n",
        "    def _gini(self, y):\n",
        "        # Gini = 1 - sum(p_k^2)\n",
        "        counts = np.bincount(y) if y.dtype == int or y.dtype == np.int64 else \\\n",
        "            np.array(list(Counter(y).values()))\n",
        "        probs = counts / len(y)\n",
        "        return 1.0 - np.sum(probs ** 2)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        # Entropy = -sum(p_k log2 p_k)\n",
        "        counts = np.bincount(y) if y.dtype == int or y.dtype == np.int64 else \\\n",
        "            np.array(list(Counter(y).values()))\n",
        "        probs = counts / len(y)\n",
        "        probs = probs[probs > 0]\n",
        "        return -np.sum(probs * np.log2(probs))\n",
        "\n",
        "    def _mse(self, y):\n",
        "        mean = np.mean(y)\n",
        "        return np.mean((y - mean) ** 2)\n",
        "\n",
        "    # --------- FIND BEST SPLIT ---------\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        parent_impurity = self._impurity(y)\n",
        "        best_gain = 0.0\n",
        "        best_feature = None\n",
        "        best_threshold = None\n",
        "\n",
        "        for feature_idx in range(n_features):  # repeat through each feature\n",
        "            values = X[:, feature_idx]\n",
        "            thresholds = np.unique(values)\n",
        "            for t in thresholds:  # try using each value that appears in the column as a threshold\n",
        "                left_mask = values <= t\n",
        "                right_mask = ~left_mask\n",
        "\n",
        "                if left_mask.sum() < self.min_samples_leaf or right_mask.sum() < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "                y_left, y_right = y[left_mask], y[right_mask]\n",
        "                impurity_left = self._impurity(y_left)\n",
        "                impurity_right = self._impurity(y_right)\n",
        "\n",
        "                p_left = len(y_left) / len(y)\n",
        "                p_right = 1.0 - p_left\n",
        "\n",
        "                gain = parent_impurity - (p_left * impurity_left + p_right * impurity_right)  # calculate branch\n",
        "\n",
        "                if gain > best_gain:\n",
        "                    best_gain = gain  # save best branch\n",
        "                    best_feature = feature_idx  # save best branch's feature\n",
        "                    best_threshold = t  # save best branch's threshold\n",
        "\n",
        "        return best_feature, best_threshold, best_gain\n",
        "\n",
        "    def _predict_one(self, x, node):  # use decision tree to predict value (or label)\n",
        "        while not node.is_leaf:\n",
        "            if x[node.feature_index] <= node.threshold:\n",
        "                node = node.left\n",
        "            else:\n",
        "                node = node.right\n",
        "        return node.value\n"
      ],
      "metadata": {
        "id": "XP0GA-79jU9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fast test Decision tree"
      ],
      "metadata": {
        "id": "RHaeVEqKnpaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "classification"
      ],
      "metadata": {
        "id": "jiIpno5MpGnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "tree_clf = DecisionTree(\n",
        "    classification=True,\n",
        "    max_depth=3,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    criterion=\"gini\",\n",
        ")\n",
        "\n",
        "tree_clf.fit(X, y)\n",
        "print(\"Predict:\", tree_clf.predict(X))\n",
        "print(\"True y :\", y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFErTjLpnRr-",
        "outputId": "d835e665-0719-4246-e86e-d8a2e1ffd89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predict: [0 1 1 1]\n",
            "True y : [0 1 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "regression"
      ],
      "metadata": {
        "id": "fkKtk7edpPt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# y = 2 * x + noise\n",
        "rng = np.random.RandomState(42)\n",
        "X_reg = rng.rand(50, 1) * 10  # 0..10\n",
        "y_reg = 2 * X_reg[:, 0] + rng.randn(50) * 0.5\n",
        "\n",
        "tree_reg = DecisionTree(\n",
        "    classification=False,\n",
        "    max_depth=3,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    criterion=\"mse\",\n",
        ")\n",
        "\n",
        "tree_reg.fit(X_reg, y_reg)\n",
        "preds = tree_reg.predict(X_reg)\n",
        "\n",
        "# caculate MSE\n",
        "mse = np.mean((preds - y_reg) ** 2)\n",
        "print(\"MSE:\", mse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMkBbvUanrZd",
        "outputId": "56698703-7dc8-4b5b-c963-32dbb572238d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.46979596460247813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "6i4k3ZvzzXEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "# import DecisionTree\n",
        "\n",
        "class RandomForest:\n",
        "    def __init__(\n",
        "        self,\n",
        "        classification: bool = True,\n",
        "        n_trees: int = 10,\n",
        "        max_depth: int = None,\n",
        "        min_samples_split: int = 2,\n",
        "        min_samples_leaf: int = 1,\n",
        "        max_features: int = None,\n",
        "        bootstrap: bool = True,\n",
        "        random_state: int = None,\n",
        "    ):\n",
        "        self.classification = classification\n",
        "        self.n_trees = n_trees # number of tree\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split  # min samples to split\n",
        "        self.min_samples_leaf = min_samples_leaf    # min sapmles in leaf\n",
        "        self.max_features = max_features            # max features to consider when looking for the best split\n",
        "        self.bootstrap = bootstrap                  # Whether to use bootstrap samples for each tree.\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.trees = []\n",
        "        self.n_features_ = None\n",
        "        self.feature_indices_per_tree = []\n",
        "\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit the Random Forest on data X, y.\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        n_samples, n_features = X.shape\n",
        "        self.n_features_ = n_features\n",
        "\n",
        "        # If max_features is None, use all features\n",
        "        if self.max_features is None or self.max_features > n_features:\n",
        "            self.max_features = n_features\n",
        "\n",
        "        self.trees = []\n",
        "        self.feature_indices_per_tree = []\n",
        "\n",
        "        for i in range(self.n_trees):\n",
        "            # Select feature subset (feature randomness)\n",
        "            feature_indices = np.random.choice(\n",
        "                n_features,\n",
        "                size=self.max_features,\n",
        "                replace=False\n",
        "            )\n",
        "            self.feature_indices_per_tree.append(feature_indices)\n",
        "\n",
        "            # Bootstrap sampling for rows\n",
        "            if self.bootstrap:\n",
        "                sample_indices = np.random.choice(\n",
        "                    n_samples,\n",
        "                    size=n_samples,\n",
        "                    replace=True\n",
        "                )\n",
        "            else:\n",
        "                sample_indices = np.arange(n_samples)\n",
        "\n",
        "            X_boot = X[sample_indices][:, feature_indices]\n",
        "            y_boot = y[sample_indices]\n",
        "\n",
        "            # Create a new DecisionTree and fit it\n",
        "            tree = DecisionTree(\n",
        "                classification=self.classification,\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                criterion=\"gini\" if self.classification else \"mse\",\n",
        "            )\n",
        "            tree.fit(X_boot, y_boot) # fit\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict for data X using all trees and aggregate the predictions.\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        # Collect predictions from each tree\n",
        "        all_preds = []\n",
        "        for tree, feat_idx in zip(self.trees, self.feature_indices_per_tree):\n",
        "            X_sub = X[:, feat_idx]\n",
        "            preds = tree.predict(X_sub)\n",
        "            all_preds.append(preds)\n",
        "\n",
        "        all_preds = np.array(all_preds)  # shape: (n_trees, n_samples)\n",
        "\n",
        "        if self.classification:\n",
        "            # Majority vote along axis 0\n",
        "            final_preds = []\n",
        "            for i in range(n_samples):\n",
        "                votes = all_preds[:, i]\n",
        "                counter = Counter(votes)\n",
        "                final_preds.append(counter.most_common(1)[0][0])\n",
        "            return np.array(final_preds)\n",
        "        else:\n",
        "            # Regression: average over trees\n",
        "            return np.mean(all_preds, axis=0)\n"
      ],
      "metadata": {
        "id": "kO8h15ix0sXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fast test Random Forest"
      ],
      "metadata": {
        "id": "dL51O_810xd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification test\n",
        "X = np.array([\n",
        "    [0, 0],\n",
        "    [0, 1],\n",
        "    [1, 0],\n",
        "    [1, 1],\n",
        "])\n",
        "y = np.array([0, 1, 1, 1])\n",
        "\n",
        "rf_clf = RandomForest(\n",
        "    classification=True,\n",
        "    n_trees=5,\n",
        "    max_depth=3,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=2,\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "rf_clf.fit(X, y)\n",
        "preds = rf_clf.predict(X)\n",
        "\n",
        "print(\"X:\")\n",
        "print(X)\n",
        "print(\"True labels :\", y)\n",
        "print(\"RF predictions:\", preds)\n",
        "print(\"Accuracy      :\", np.mean(preds == y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btwa3J67009G",
        "outputId": "4a3b7b10-fe76-4632-811c-50463c5f64ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X:\n",
            "[[0 0]\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 1]]\n",
            "True labels : [0 1 1 1]\n",
            "RF predictions: [0 1 1 1]\n",
            "Accuracy      : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toy regression: y = 2 * x + noise\n",
        "rng = np.random.RandomState(42)\n",
        "X_reg = rng.rand(100, 1) * 10  # range 0..10\n",
        "y_reg = 2 * X_reg[:, 0] + rng.randn(100) * 0.5\n",
        "\n",
        "rf_reg = RandomForest(\n",
        "    classification=False,\n",
        "    n_trees=10,\n",
        "    max_depth=5,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    max_features=1,\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "rf_reg.fit(X_reg, y_reg)\n",
        "preds_reg = rf_reg.predict(X_reg)\n",
        "\n",
        "mse_rf = np.mean((preds_reg - y_reg) ** 2)\n",
        "print(\"RandomForest Regression MSE:\", mse_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l-qnQro04KN",
        "outputId": "556c5c3b-4410-402a-9144-df2f04a59cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Regression MSE: 0.1050399719860864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Boosting"
      ],
      "metadata": {
        "id": "Sk8o3yJB7EUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# import DecisionTree\n",
        "\n",
        "class GradientBoosting:\n",
        "    def __init__(\n",
        "        self,\n",
        "        classification: bool = True,\n",
        "        n_estimators: int = 50,\n",
        "        learning_rate: float = 0.1,\n",
        "        max_depth: int = 3,\n",
        "        min_samples_split: int = 2,\n",
        "        min_samples_leaf: int = 1,\n",
        "        random_state: int = None,\n",
        "    ):\n",
        "        self.classification = classification\n",
        "        self.n_estimators = n_estimators    #  Number of boosting stages (trees).\n",
        "        self.learning_rate = learning_rate  # each tree contributes 'lr' its predict's turn number\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.random_state = random_state\n",
        "\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "\n",
        "        self.trees = []          # list of trained tree\n",
        "        self.init_value_ = None  # initial prediction (bias term)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Fit Gradient Boosting model on data X, y.\n",
        "        Uses MSE loss for both regression and binary classification (0/1).\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        y = np.array(y, dtype=float)  # cast to float for regression-style updates\n",
        "\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        # Initialize prediction:\n",
        "        # For regression: mean of y\n",
        "        # For binary classification: mean of y in [0, 1] range (approximate prob)\n",
        "        self.init_value_ = np.mean(y)\n",
        "        current_pred = np.full(n_samples, self.init_value_, dtype=float)\n",
        "\n",
        "        self.trees = []\n",
        "\n",
        "        for m in range(self.n_estimators):  # for each tree\n",
        "            # Residuals for MSE: r = y - y_pred\n",
        "            residuals = y - current_pred\n",
        "\n",
        "            # Train a small regression tree on residuals\n",
        "            tree = DecisionTree(\n",
        "                classification=False,  # always regression tree for residuals\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                criterion=\"mse\",\n",
        "            )\n",
        "            tree.fit(X, residuals)\n",
        "\n",
        "            # Get tree predictions\n",
        "            tree_pred = tree.predict(X)\n",
        "\n",
        "            # Update current predictions\n",
        "            current_pred += self.learning_rate * tree_pred\n",
        "\n",
        "            # Store tree\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def _raw_predict(self, X):\n",
        "        \"\"\"\n",
        "        Compute raw prediction (regression output) before any thresholding.\n",
        "        \"\"\"\n",
        "        X = np.array(X)\n",
        "        # Start with initial value\n",
        "        pred = np.full(X.shape[0], self.init_value_, dtype=float)\n",
        "        # Add contributions from all trees\n",
        "        for tree in self.trees:\n",
        "            pred += self.learning_rate * tree.predict(X)\n",
        "        return pred\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict for data X.\n",
        "\n",
        "        For regression: return raw predictions.\n",
        "        For classification: return class labels 0 or 1 (binary).\n",
        "        \"\"\"\n",
        "        raw_pred = self._raw_predict(X)\n",
        "\n",
        "        if self.classification:\n",
        "            # Binary classification: threshold at 0.5\n",
        "            return (raw_pred >= 0.5).astype(int)\n",
        "        else:\n",
        "            # Regression: return continuous value\n",
        "            return raw_pred\n"
      ],
      "metadata": {
        "id": "HHSJS6tp7KDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fast test GB"
      ],
      "metadata": {
        "id": "N8gx4qSa8wup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple binary classification toy data\n",
        "rng = np.random.RandomState(0)\n",
        "n_samples = 200\n",
        "\n",
        "# Class 0 around (0,0)\n",
        "X0 = rng.randn(n_samples // 2, 2) + np.array([-1, -1])\n",
        "y0 = np.zeros(n_samples // 2, dtype=int)\n",
        "\n",
        "# Class 1 around (2,2)\n",
        "X1 = rng.randn(n_samples // 2, 2) + np.array([2, 2])\n",
        "y1 = np.ones(n_samples // 2, dtype=int)\n",
        "\n",
        "X_clf = np.vstack([X0, X1])\n",
        "y_clf = np.concatenate([y0, y1])\n",
        "\n",
        "gb_clf = GradientBoosting(\n",
        "    classification=True,\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "gb_clf.fit(X_clf, y_clf)\n",
        "preds_clf = gb_clf.predict(X_clf)\n",
        "\n",
        "acc = np.mean(preds_clf == y_clf)\n",
        "print(\"GradientBoosting Classification Accuracy:\", acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Au2Ac98zPq",
        "outputId": "5c2139db-4c12-4e0b-a73d-6b385d54a2a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoosting Classification Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Toy regression: y = 2 * x + noise\n",
        "rng = np.random.RandomState(42)\n",
        "X_reg = rng.rand(200, 1) * 10  # range 0..10\n",
        "y_reg = 2 * X_reg[:, 0] + rng.randn(200) * 0.5\n",
        "\n",
        "gb_reg = GradientBoosting(\n",
        "    classification=False,\n",
        "    n_estimators=50,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_split=2,\n",
        "    min_samples_leaf=1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "gb_reg.fit(X_reg, y_reg)\n",
        "preds_reg = gb_reg.predict(X_reg)\n",
        "\n",
        "mse_gb = np.mean((preds_reg - y_reg) ** 2)\n",
        "print(\"GradientBoosting Regression MSE:\", mse_gb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rg9elgO84F-",
        "outputId": "1361a6bd-8f34-4953-9757-75b6f60f749e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GradientBoosting Regression MSE: 0.11912061804868895\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work with dataset London-Bike"
      ],
      "metadata": {
        "id": "lR5eJrDZFIlI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing steps"
      ],
      "metadata": {
        "id": "t9YWwf4LHxkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset from file CSV (London Bike)"
      ],
      "metadata": {
        "id": "5VPZ78KhFuQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_path = \"/content/london_merged.csv\"  # adjust if needed\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "\n",
        "# timestamp - time\n",
        "# cnt - count of a new bike shares\n",
        "# t1 - real temperature in C\n",
        "# t2 - temperature in C \"feels like\"\n",
        "# hum - humidity in percentage\n",
        "# wind_speed - wind speed in km/h\n",
        "# weather_code - category of the weather\n",
        "# is_holiday - boolean field - 1 holiday / 0 non holiday\n",
        "# is_weekend -  boolean field - 1 if the day is weekend\n",
        "# season - 0-spring ; 1-summer; 2-fall; 3-winter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YOkPYD66FJO9",
        "outputId": "e5762726-bdc8-44d5-d262-039598b0321e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             timestamp  cnt   t1   t2    hum  wind_speed  weather_code  \\\n",
              "0  2015-01-04 00:00:00  182  3.0  2.0   93.0         6.0           3.0   \n",
              "1  2015-01-04 01:00:00  138  3.0  2.5   93.0         5.0           1.0   \n",
              "2  2015-01-04 02:00:00  134  2.5  2.5   96.5         0.0           1.0   \n",
              "3  2015-01-04 03:00:00   72  2.0  2.0  100.0         0.0           1.0   \n",
              "4  2015-01-04 04:00:00   47  2.0  0.0   93.0         6.5           1.0   \n",
              "\n",
              "   is_holiday  is_weekend  season  \n",
              "0         0.0         1.0     3.0  \n",
              "1         0.0         1.0     3.0  \n",
              "2         0.0         1.0     3.0  \n",
              "3         0.0         1.0     3.0  \n",
              "4         0.0         1.0     3.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e50457b7-c010-45ba-9147-0e551d6b8f6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>cnt</th>\n",
              "      <th>t1</th>\n",
              "      <th>t2</th>\n",
              "      <th>hum</th>\n",
              "      <th>wind_speed</th>\n",
              "      <th>weather_code</th>\n",
              "      <th>is_holiday</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>season</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-01-04 00:00:00</td>\n",
              "      <td>182</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2015-01-04 01:00:00</td>\n",
              "      <td>138</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>93.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2015-01-04 02:00:00</td>\n",
              "      <td>134</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>96.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2015-01-04 03:00:00</td>\n",
              "      <td>72</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2015-01-04 04:00:00</td>\n",
              "      <td>47</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>93.0</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e50457b7-c010-45ba-9147-0e551d6b8f6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e50457b7-c010-45ba-9147-0e551d6b8f6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e50457b7-c010-45ba-9147-0e551d6b8f6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5a193d9f-727f-49f0-91aa-8ee7c43a1bdf\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5a193d9f-727f-49f0-91aa-8ee7c43a1bdf')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5a193d9f-727f-49f0-91aa-8ee7c43a1bdf button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"# season - 0-spring ; 1-summer; 2-fall; 3-winter\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2015-01-04 01:00:00\",\n          \"2015-01-04 04:00:00\",\n          \"2015-01-04 02:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cnt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 47,\n        \"max\": 182,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          138,\n          47,\n          134\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5,\n        \"min\": 2.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3.0,\n          2.5,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.036822067666386,\n        \"min\": 0.0,\n        \"max\": 2.5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.0,\n          2.5,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.1304951684997055,\n        \"min\": 93.0,\n        \"max\": 100.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          93.0,\n          96.5,\n          100.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wind_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.24037034920393,\n        \"min\": 0.0,\n        \"max\": 6.5,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          5.0,\n          6.5,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"weather_code\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8944271909999161,\n        \"min\": 1.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_holiday\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"is_weekend\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"season\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 3.0,\n        \"max\": 3.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "choose features & target; preprocessing data\n",
        "* target: cnt"
      ],
      "metadata": {
        "id": "QqM5UuzEGo1z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose target column (bike count)\n",
        "target_col = \"cnt\"\n",
        "\n",
        "# Choose a set of numeric and categorical features\n",
        "feature_cols = [\n",
        "    \"t1\",           # real temperature\n",
        "    \"t2\",           # feels-like temperature\n",
        "    \"hum\",          # humidity\n",
        "    \"wind_speed\",   # wind speed\n",
        "    \"weather_code\", # weather condition code\n",
        "    \"is_holiday\",\n",
        "    \"is_weekend\",\n",
        "    \"season\",\n",
        "]\n",
        "\n",
        "# Filter dataframe (drop rows with missing values just in case)\n",
        "df_model = df[feature_cols + [target_col]].dropna()\n",
        "\n",
        "X = df_model[feature_cols].values\n",
        "y = df_model[target_col].values\n",
        "\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRSDn2fjGWga",
        "outputId": "2087e5cf-8459-47f5-fc60-90cc6440ddfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (17414, 8)\n",
            "y shape: (17414,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "split train & test samples"
      ],
      "metadata": {
        "id": "1eHEAdrDHBVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Train size:\", X_train.shape[0])\n",
        "print(\"Test size :\", X_test.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qUR9KzwG9V6",
        "outputId": "8291e5a9-ce70-4502-f41c-2ac20140d951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 13931\n",
            "Test size : 3483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "9qjJbwwZJ-dl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regression_metrics(y_true, y_pred):\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    rmse = np.sqrt(mse)\n",
        "\n",
        "    ss_res = np.sum((y_true - y_pred) ** 2)\n",
        "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else 0.0\n",
        "\n",
        "    return {\n",
        "        \"MAE\": float(mae),\n",
        "        \"MSE\": float(mse),\n",
        "        \"RMSE\": float(rmse),\n",
        "        \"R2\": float(r2),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "zZwrjOmSKBM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with DecisionTree"
      ],
      "metadata": {
        "id": "b3IFBr-5HsmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree Regressor\n",
        "dt_reg = DecisionTree(\n",
        "    classification=False,\n",
        "    max_depth=6,           # can tune this\n",
        "    min_samples_split=10,  # to avoid overfitting\n",
        "    min_samples_leaf=5,\n",
        "    criterion=\"mse\",\n",
        ")\n",
        "\n",
        "dt_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on train and test\n",
        "y_train_pred_dt = dt_reg.predict(X_train)\n",
        "y_test_pred_dt = dt_reg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "_YzperrOHsD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with RandomForest"
      ],
      "metadata": {
        "id": "jY3QVywQIBvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor using our custom RandomForest\n",
        "rf_reg = RandomForest(\n",
        "    classification=False,\n",
        "    n_trees=10,           # can be increased if it is not too slow\n",
        "    max_depth=6,\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    max_features=None,    # use all features here\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "rf_reg.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_rf = rf_reg.predict(X_train)\n",
        "y_test_pred_rf = rf_reg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "O3bFmsAzIBdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with GradientBoosting"
      ],
      "metadata": {
        "id": "6Vz8lwWYIPLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gb_reg = GradientBoosting(\n",
        "    classification=False,\n",
        "    n_estimators=50,   # number of boosting stages\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,       # shallow trees as \"stumps\"\n",
        "    min_samples_split=10,\n",
        "    min_samples_leaf=5,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "gb_reg.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred_gb = gb_reg.predict(X_train)\n",
        "y_test_pred_gb = gb_reg.predict(X_test)\n"
      ],
      "metadata": {
        "id": "PBXarNeIHId5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric comparison  "
      ],
      "metadata": {
        "id": "KcIgYJklKupU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== London Bike Regression: Comparison ===\")\n",
        "\n",
        "print(\"=== DecisionTree Regression metrics ===\")\n",
        "dt_train_metrics = regression_metrics(y_train, y_train_pred_dt)\n",
        "dt_test_metrics  = regression_metrics(y_test,  y_test_pred_dt)\n",
        "# print(\"Train:\", dt_train_metrics)\n",
        "print(\"Test :\", dt_test_metrics)\n",
        "print()\n",
        "\n",
        "print(\"=== RandomForest Regression metrics ===\")\n",
        "rf_train_metrics = regression_metrics(y_train, y_train_pred_rf)\n",
        "rf_test_metrics  = regression_metrics(y_test,  y_test_pred_rf)\n",
        "# print(\"Train:\", rf_train_metrics)\n",
        "print(\"Test :\", rf_test_metrics)\n",
        "print()\n",
        "\n",
        "print(\"=== GradientBoosting Regression metrics ===\")\n",
        "gb_train_metrics = regression_metrics(y_train, y_train_pred_gb)\n",
        "gb_test_metrics  = regression_metrics(y_test,  y_test_pred_gb)\n",
        "# print(\"Train:\", gb_train_metrics)\n",
        "print(\"Test :\", gb_test_metrics)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGUWHqLQIYD2",
        "outputId": "0e7b24e7-3096-4573-b3c6-6c34ec3832d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== London Bike Regression: Comparison ===\n",
            "=== DecisionTree Regression metrics ===\n",
            "Test : {'MAE': 667.2574515022576, 'MSE': 848428.6819700071, 'RMSE': 921.1018846848633, 'R2': 0.29193936375589336}\n",
            "\n",
            "=== RandomForest Regression metrics ===\n",
            "Test : {'MAE': 658.6768159233443, 'MSE': 826972.0131750309, 'RMSE': 909.3800158212357, 'R2': 0.30984613999001753}\n",
            "\n",
            "=== GradientBoosting Regression metrics ===\n",
            "Test : {'MAE': 658.3612702538719, 'MSE': 825637.2993238627, 'RMSE': 908.6458602359131, 'R2': 0.3109600324818034}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Анализ результатов на датасете London-Bike**\n",
        "### **1. DecisionTree**\n",
        "\n",
        "* Одиночное дерево имеет **высокую дисперсию**.\n",
        "* Оно слишком точно подстраивается под шум обучающей выборки.\n",
        "* Способность к обобщению низкая.\n",
        "* Это — хорошо известный недостаток классических решающих деревьев.\n",
        "\n",
        "\n",
        "### **2. RandomForest**\n",
        "\n",
        "* RandomForest **снижает дисперсию** модели.\n",
        "* Выполняет усреднение предсказаний большого числа независимых деревьев.\n",
        "* Bootstrap-выборки помогают избежать переобучения.\n",
        "* Предсказания получаются более стабильными.\n",
        "\n",
        "\n",
        "### **3. GradientBoosting**\n",
        "\n",
        "* Boosting учит деревья **на остатках (residuals)**, постепенно улучшая модель.\n",
        "* Это последовательная схема обучения, исправляющая ошибки предыдущих деревьев.\n",
        "* Подходит для **нелинейных регрессионных задач**.\n",
        "* Параметры *learning rate = 0.1* и *max_depth = 3* дают хороший баланс качества и устойчивости.\n",
        "* Переобучения удаётся избежать, если число этапов (деревьев) не слишком велико.\n",
        "\n",
        "\n",
        "## **Вывод**: DecisionTree < RandomForest < GradientBoosting\n"
      ],
      "metadata": {
        "id": "zvcIzmF0Lq1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Work with dataset CIFAR"
      ],
      "metadata": {
        "id": "BF9gpWmqPB1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing steps"
      ],
      "metadata": {
        "id": "UfOTBv3iRtWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Load dataset"
      ],
      "metadata": {
        "id": "y8uJ1B93RlIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzf cifar-10-python.tar.gz -C /content/\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VarTm8SfPzj6",
        "outputId": "3103875c-852e-4c21-badd-9b8f09a74267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar-10-batches-py  cifar-10-python.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "function load 1 batch CIFAR-10"
      ],
      "metadata": {
        "id": "iV-qCD_AQw1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cifar_batch(file_path):\n",
        "    \"\"\"\n",
        "    Load a single CIFAR-10 batch file.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'rb') as f:\n",
        "        batch = pickle.load(f, encoding='latin1')  # encoding for Python3\n",
        "\n",
        "    data = batch['data']            # shape (10000, 3072)\n",
        "    labels = batch['labels']        # list of int labels (0..9)\n",
        "    data = np.array(data, dtype=np.uint8)\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "    return data, labels\n"
      ],
      "metadata": {
        "id": "zTH4K17gQrEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all train + test CIFAR-10"
      ],
      "metadata": {
        "id": "zjVFHtJiQ7gg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cifar_dir = \"/content/cifar-10-batches-py\"\n",
        "\n",
        "# Load train batches (data_batch_1..5)\n",
        "X_list = []\n",
        "y_list = []\n",
        "\n",
        "for i in range(1, 6):\n",
        "    batch_path = os.path.join(cifar_dir, f\"data_batch_{i}\")\n",
        "    X_batch, y_batch = load_cifar_batch(batch_path)\n",
        "    X_list.append(X_batch)\n",
        "    y_list.append(y_batch)\n",
        "\n",
        "X_train_full = np.vstack(X_list)           # shape (50000, 3072)\n",
        "y_train_full = np.concatenate(y_list)      # shape (50000,)\n",
        "\n",
        "print(\"Train full shape:\", X_train_full.shape, y_train_full.shape)\n",
        "\n",
        "# Load test batch\n",
        "test_path = os.path.join(cifar_dir, \"test_batch\")\n",
        "X_test_full, y_test_full = load_cifar_batch(test_path)\n",
        "\n",
        "print(\"Test full shape:\", X_test_full.shape, y_test_full.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkxut212Q61l",
        "outputId": "8dbe00ae-98ec-4d7b-f5d1-7494a0599381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train full shape: (50000, 3072) (50000,)\n",
            "Test full shape: (10000, 3072) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing data"
      ],
      "metadata": {
        "id": "c_90bSFbRzcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to float32 and normalize to [0, 1]\n",
        "X_train_full = X_train_full.astype(np.float32) / 255.0\n",
        "X_test_full  = X_test_full.astype(np.float32) / 255.0\n",
        "\n",
        "print(\"After normalization:\")\n",
        "print(\"Train full:\", X_train_full.shape, X_train_full.dtype)\n",
        "print(\"Test full :\", X_test_full.shape, X_test_full.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlYzWWCAR4kP",
        "outputId": "9ffe9359-0eb1-456c-fd61-57d126577a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After normalization:\n",
            "Train full: (50000, 3072) float32\n",
            "Test full : (10000, 3072) float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utils"
      ],
      "metadata": {
        "id": "PbXOlSLQSuY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Simple accuracy: percentage of correct predictions.\n",
        "    \"\"\"\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    return np.mean(y_true == y_pred)"
      ],
      "metadata": {
        "id": "XMlVCu4vStT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose a smaller, balanced CIFAR-10 subset between classes, randomly controlled,"
      ],
      "metadata": {
        "id": "IITuUSbJT0gP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_balanced(X, y, n_per_class, random_state=42):\n",
        "    \"\"\"\n",
        "    Sample n_per_class examples for each class (0..9) from X, y.\n",
        "    \"\"\"\n",
        "    rng = np.random.RandomState(random_state)\n",
        "    classes = np.unique(y)\n",
        "    X_out = []\n",
        "    y_out = []\n",
        "\n",
        "    for c in classes:\n",
        "        idx = np.where(y == c)[0]\n",
        "        if len(idx) < n_per_class:\n",
        "            raise ValueError(f\"Not enough samples for class {c}\")\n",
        "        chosen = rng.choice(idx, size=n_per_class, replace=False)\n",
        "        X_out.append(X[chosen])\n",
        "        y_out.append(y[chosen])\n",
        "\n",
        "    X_out = np.vstack(X_out)\n",
        "    y_out = np.concatenate(y_out)\n",
        "    return X_out, y_out\n",
        "\n",
        "# Choose how many per class\n",
        "n_train_per_class = 300   # => * 10 train\n",
        "n_test_per_class  = 100    # => * 10 test\n",
        "\n",
        "X_train_small, y_train_small = sample_balanced(X_train_full, y_train_full, n_train_per_class, random_state=0)\n",
        "X_test_small,  y_test_small  = sample_balanced(X_test_full,  y_test_full,  n_test_per_class,  random_state=1)\n",
        "\n",
        "print(\"Small train:\", X_train_small.shape, y_train_small.shape)\n",
        "print(\"Small test :\", X_test_small.shape,  y_test_small.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdYGceh_T1VK",
        "outputId": "a3d6dab0-63d4-454d-e231-345ace140319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Small train: (2000, 3072) (2000,)\n",
            "Small test : (1000, 3072) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with DecisionTree"
      ],
      "metadata": {
        "id": "4K01ESpPT5YK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_cifar = DecisionTree(\n",
        "    classification=True,\n",
        "    max_depth=12,        # a little more\n",
        "    min_samples_split=30,\n",
        "    min_samples_leaf=8,\n",
        "    criterion=\"gini\",\n",
        ")\n",
        "\n",
        "print(\"Training DecisionTree on CIFAR-10 subset...\")\n",
        "dt_cifar.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_train_pred_dt = dt_cifar.predict(X_train_small)\n",
        "y_test_pred_dt  = dt_cifar.predict(X_test_small)\n",
        "\n",
        "acc_train_dt = accuracy_score(y_train_small, y_train_pred_dt)\n",
        "acc_test_dt  = accuracy_score(y_test_small,  y_test_pred_dt)\n",
        "\n",
        "print(\"DecisionTree CIFAR-10\")\n",
        "print(\"Train accuracy:\", acc_train_dt)\n",
        "print(\"Test  accuracy:\", acc_test_dt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftzCXz_iCxtz",
        "outputId": "028dbf26-3361-45e0-f21e-60827cd417cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DecisionTree on CIFAR-10 subset...\n",
            "DecisionTree CIFAR-10\n",
            "Train accuracy: 0.566\n",
            "Test  accuracy: 0.218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree for CIFAR-10\n",
        "dt_cifar = DecisionTree(\n",
        "    classification=True,\n",
        "    max_depth=10,\n",
        "    min_samples_split=50,\n",
        "    min_samples_leaf=20,\n",
        "    criterion=\"gini\",\n",
        ")\n",
        "\n",
        "print(\"Training DecisionTree on CIFAR-10 subset...\")\n",
        "dt_cifar.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_train_pred_dt = dt_cifar.predict(X_train_small)\n",
        "y_test_pred_dt  = dt_cifar.predict(X_test_small)\n",
        "\n",
        "acc_train_dt = accuracy_score(y_train_small, y_train_pred_dt)\n",
        "acc_test_dt  = accuracy_score(y_test_small,  y_test_pred_dt)\n",
        "\n",
        "print(\"DecisionTree CIFAR-10\")\n",
        "print(\"Train accuracy:\", acc_train_dt)\n",
        "print(\"Test  accuracy:\", acc_test_dt)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R1YClQ4T5rd",
        "outputId": "b214f480-2521-4d68-85c7-a3491b358700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training DecisionTree on CIFAR-10 subset...\n",
            "DecisionTree CIFAR-10\n",
            "Train accuracy: 0.472\n",
            "Test  accuracy: 0.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with RandomForest"
      ],
      "metadata": {
        "id": "Zl-ufibqUKez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest for CIFAR-10\n",
        "rf_cifar = RandomForest(\n",
        "    classification=True,\n",
        "    n_trees=10,\n",
        "    max_depth=12,\n",
        "    min_samples_split=40,\n",
        "    min_samples_leaf=10,\n",
        "    max_features=64,\n",
        "    bootstrap=True,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Training RandomForest on CIFAR-10 subset...\")\n",
        "rf_cifar.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_train_pred_rf = rf_cifar.predict(X_train_small)\n",
        "y_test_pred_rf  = rf_cifar.predict(X_test_small)\n",
        "\n",
        "acc_train_rf = accuracy_score(y_train_small, y_train_pred_rf)\n",
        "acc_test_rf  = accuracy_score(y_test_small,  y_test_pred_rf)\n",
        "\n",
        "print(\"RandomForest CIFAR-10\")\n",
        "print(\"Train accuracy:\", acc_train_rf)\n",
        "print(\"Test  accuracy:\", acc_test_rf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moeQ95d7Umfe",
        "outputId": "52a3403f-64a0-45d1-f4fb-eeb253397506"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RandomForest on CIFAR-10 subset...\n",
            "RandomForest CIFAR-10\n",
            "Train accuracy: 0.6145\n",
            "Test  accuracy: 0.269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train with Gradient Boostring"
      ],
      "metadata": {
        "id": "XVOF_QmnUnXl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Method “One-vs-Rest”**:\n",
        "\n",
        "Separate the multi-layered problem into multiple binary problems.\n",
        "For each class c, see:\n",
        "\n",
        "* class c → label 1\n",
        "\n",
        "* other class → label 0"
      ],
      "metadata": {
        "id": "dDr_btJcW894"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneVsRestGB:\n",
        "    def __init__(self, n_classes, n_estimators=20, learning_rate=0.1,\n",
        "                 max_depth=3, min_samples_split=10, min_samples_leaf=5,\n",
        "                 random_state=42):\n",
        "        \"\"\"\n",
        "        One-vs-Rest wrapper for GradientBoosting on multi-class tasks.\n",
        "        Trains one regression boosting model per class.\n",
        "        \"\"\"\n",
        "        self.n_classes = n_classes\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.random_state = random_state\n",
        "        self.models = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.array(X)\n",
        "        y = np.array(y)\n",
        "        self.models = []\n",
        "\n",
        "        for c in range(self.n_classes):\n",
        "            # Binary labels: 1 for class c, 0 for others\n",
        "            y_bin = (y == c).astype(float)\n",
        "            gb = GradientBoosting(\n",
        "                classification=False,          # use regression mode on 0/1\n",
        "                n_estimators=self.n_estimators,\n",
        "                learning_rate=self.learning_rate,\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split,\n",
        "                min_samples_leaf=self.min_samples_leaf,\n",
        "                random_state=self.random_state,\n",
        "            )\n",
        "            gb.fit(X, y_bin)\n",
        "            self.models.append(gb)\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        # For each class model, get raw prediction (probability-like score)\n",
        "        scores = []\n",
        "        for gb in self.models:\n",
        "            s = gb._raw_predict(X)          # shape (n_samples,)\n",
        "            scores.append(s)\n",
        "        scores = np.vstack(scores).T        # shape (n_samples, n_classes)\n",
        "        # Choose class with highest score\n",
        "        return np.argmax(scores, axis=1)\n"
      ],
      "metadata": {
        "id": "eOlpQLHdW8Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "I5VdC6Q1Xo_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = len(np.unique(y_train_small))\n",
        "\n",
        "gb_cifar = OneVsRestGB(\n",
        "    n_classes=10,\n",
        "    n_estimators=8,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=3,\n",
        "    min_samples_split=50,\n",
        "    min_samples_leaf=20,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(\"Training GradientBoosting (One-vs-Rest) on CIFAR-10 subset...\")\n",
        "gb_cifar.fit(X_train_small, y_train_small)\n",
        "\n",
        "y_train_pred_gb = gb_cifar.predict(X_train_small)\n",
        "y_test_pred_gb  = gb_cifar.predict(X_test_small)\n",
        "\n",
        "acc_train_gb = accuracy_score(y_train_small, y_train_pred_gb)\n",
        "acc_test_gb  = accuracy_score(y_test_small,  y_test_pred_gb)\n",
        "\n",
        "print(\"GradientBoosting (OvR) CIFAR-10\")\n",
        "print(\"Train accuracy:\", acc_train_gb)\n",
        "print(\"Test  accuracy:\", acc_test_gb)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQK4EgtqXrQ5",
        "outputId": "c9f97195-a96c-444a-cb4d-aabb806bab5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GradientBoosting (One-vs-Rest) on CIFAR-10 subset...\n",
            "GradientBoosting (OvR) CIFAR-10\n",
            "Train accuracy: 0.623\n",
            "Test  accuracy: 0.308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Metric comparison"
      ],
      "metadata": {
        "id": "EYjt7eW_XwmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=== CIFAR-10 Accuracy Comparison (subset) ===\")\n",
        "print(f\"DecisionTree   - Train: {acc_train_dt:.4f} | Test: {acc_test_dt:.4f}\")\n",
        "print(f\"RandomForest   - Train: {acc_train_rf:.4f} | Test: {acc_test_rf:.4f}\")\n",
        "print(f\"GradientBoost. - Train: {acc_train_gb:.4f} | Test: {acc_test_gb:.4f}\")"
      ],
      "metadata": {
        "id": "6WmQla3DX29t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bb2181-5873-4dc3-9949-04c61de20d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CIFAR-10 Accuracy Comparison (subset) ===\n",
            "DecisionTree   - Train: 0.4720 | Test: 0.2250\n",
            "RandomForest   - Train: 0.6145 | Test: 0.2690\n",
            "GradientBoost. - Train: 0.6230 | Test: 0.3080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## **Анализ результатов на датасете CIFAR-10**\n",
        "\n",
        "\n",
        "### **1. DecisionTree**\n",
        "\n",
        "* *Train accuracy = 0.472*, *Test accuracy = 0.225*.\n",
        "* Одиночное дерево сильно ограничено на задачах с высокоразмерными данными (3072 признака).\n",
        "* Модель имеет высокую дисперсию и переобучается, даже несмотря на ограничения глубины.\n",
        "* Способность к обобщению низкая, поэтому тестовая точность остаётся около 22–23%.\n",
        "\n",
        "### **2. RandomForest**\n",
        "\n",
        "* *Train accuracy = 0.6145*, *Test accuracy = 0.269*.\n",
        "* За счёт bagging и случайного подбора признаков RandomForest существенно уменьшает дисперсию по сравнению с одиночным деревом.\n",
        "* Модель становится более устойчивой и менее чувствительной к шуму.\n",
        "* Улучшение тестовой точности до ~0.27 подтверждает, что ансамбль деревьев обобщает данные лучше, чем одно дерево.\n",
        "\n",
        "### **3. GradientBoosting**\n",
        "\n",
        "* *Train accuracy = 0.623*, *Test accuracy = 0.308*.\n",
        "* Boosting обучается последовательно, исправляя ошибки предыдущих деревьев, что позволяет моделировать более сложные нелинейные зависимости.\n",
        "* Несмотря на небольшую глубину деревьев, boosting эффективно адаптируется под структуру данных.\n",
        "* Лучшая тестовая точность (~0.31) показывает, что модель наиболее хорошо захватывает информативные признаки даже при ограниченной выборке.\n",
        "\n",
        "\n",
        "\n",
        "## **Вывод**: DecisionTree < RandomForest < GradientBoosting\n"
      ],
      "metadata": {
        "id": "5j-pG9XhN_Ng"
      }
    }
  ]
}