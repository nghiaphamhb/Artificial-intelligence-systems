{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-NlTk1UtyvB"
      },
      "source": [
        "# Лабораторная работа 3\n",
        "\n",
        "## ФИО: Фам Данг Чунг Нгиа\n",
        "\n",
        "##Группа: P3321\n",
        "\n",
        "## ИСу 374806"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz8owv3IuV1s"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbjthIb7rvuS"
      },
      "source": [
        "### Installing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "hxaTEmgtVzZk",
        "outputId": "53506b3f-945c-41ac-bff3-384e8c2381bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (25.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (80.9.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (0.45.1)\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting pandas==2.2.2\n",
            "  Downloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting mne==1.10.2\n",
            "  Downloading mne-1.10.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting pyriemann==0.7\n",
            "  Downloading pyriemann-0.7-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting moabb==1.2.0\n",
            "  Downloading moabb-1.2.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting scikit-learn==1.5.2\n",
            "  Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting matplotlib==3.9.2\n",
            "  Downloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas==2.2.2)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas==2.2.2)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas==2.2.2)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting decorator (from mne==1.10.2)\n",
            "  Downloading decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting jinja2 (from mne==1.10.2)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting lazy-loader>=0.3 (from mne==1.10.2)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting packaging (from mne==1.10.2)\n",
            "  Downloading packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting pooch>=1.5 (from mne==1.10.2)\n",
            "  Downloading pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting tqdm (from mne==1.10.2)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting joblib (from pyriemann==0.7)\n",
            "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting PyYAML<7.0,>=6.0 (from moabb==1.2.0)\n",
            "  Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting coverage<8.0.0,>=7.0.1 (from moabb==1.2.0)\n",
            "  Downloading coverage-7.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting edfio<0.5.0,>=0.4.2 (from moabb==1.2.0)\n",
            "  Downloading edfio-0.4.11-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting edflib-python<2.0.0,>=1.0.6 (from moabb==1.2.0)\n",
            "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting h5py<4.0.0,>=3.10.0 (from moabb==1.2.0)\n",
            "  Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting memory-profiler<0.62.0,>=0.61.0 (from moabb==1.2.0)\n",
            "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting mne-bids>=0.14 (from moabb==1.2.0)\n",
            "  Downloading mne_bids-0.17.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting requests<3.0.0,>=2.28.1 (from moabb==1.2.0)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting seaborn<0.13.0,>=0.12.1 (from moabb==1.2.0)\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting urllib3<2.0.0,>=1.26.15 (from moabb==1.2.0)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn==1.5.2)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib==3.9.2)\n",
            "  Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.9.2)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.9.2)\n",
            "  Downloading fonttools-4.61.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (113 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib==3.9.2)\n",
            "  Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
            "Collecting pillow>=8 (from matplotlib==3.9.2)\n",
            "  Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib==3.9.2)\n",
            "  Downloading pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting psutil (from memory-profiler<0.62.0,>=0.61.0->moabb==1.2.0)\n",
            "  Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl.metadata (23 kB)\n",
            "Collecting platformdirs>=2.5.0 (from pooch>=1.5->mne==1.10.2)\n",
            "  Downloading platformdirs-4.5.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.28.1->moabb==1.2.0)\n",
            "  Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.28.1->moabb==1.2.0)\n",
            "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.28.1->moabb==1.2.0)\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas==2.2.2)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->mne==1.10.2)\n",
            "  Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (2.7 kB)\n",
            "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m189.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m367.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m324.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mne-1.10.2-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyriemann-0.7-py2.py3-none-any.whl (115 kB)\n",
            "Downloading moabb-1.2.0-py3-none-any.whl (242 kB)\n",
            "Downloading scikit_learn-1.5.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m348.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading matplotlib-3.9.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m243.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coverage-7.12.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (252 kB)\n",
            "Downloading edfio-0.4.11-py3-none-any.whl (29 kB)\n",
            "Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
            "Downloading h5py-3.15.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m180.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
            "Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Downloading pyyaml-6.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (807 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m807.9/807.9 kB\u001b[0m \u001b[31m219.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Downloading charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "Downloading contourpy-1.3.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
            "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.61.0-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m342.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Downloading kiwisolver-1.4.9-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m184.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading mne_bids-0.17.0-py3-none-any.whl (168 kB)\n",
            "Downloading packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Downloading pillow-12.0.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m281.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.5.1-py3-none-any.whl (18 kB)\n",
            "Downloading pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Downloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Downloading decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
            "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Downloading markupsafe-3.0.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (22 kB)\n",
            "Downloading psutil-7.1.3-cp36-abi3-manylinux2010_x86_64.manylinux_2_12_x86_64.manylinux_2_28_x86_64.whl (263 kB)\n",
            "Installing collected packages: pytz, urllib3, tzdata, tqdm, threadpoolctl, six, PyYAML, pyparsing, psutil, platformdirs, pillow, packaging, numpy, MarkupSafe, kiwisolver, joblib, idna, fonttools, decorator, cycler, coverage, charset_normalizer, certifi, scipy, requests, python-dateutil, memory-profiler, lazy-loader, jinja2, h5py, edflib-python, edfio, contourpy, scikit-learn, pooch, pandas, matplotlib, seaborn, pyriemann, mne, mne-bids, moabb\n",
            "\u001b[2K  Attempting uninstall: pytz\n",
            "\u001b[2K    Found existing installation: pytz 2025.2\n",
            "\u001b[2K    Uninstalling pytz-2025.2:\n",
            "\u001b[2K      Successfully uninstalled pytz-2025.2\n",
            "\u001b[2K  Attempting uninstall: urllib3\n",
            "\u001b[2K    Found existing installation: urllib3 2.5.0\n",
            "\u001b[2K    Uninstalling urllib3-2.5.0:\n",
            "\u001b[2K      Successfully uninstalled urllib3-2.5.0\n",
            "\u001b[2K  Attempting uninstall: tzdata\n",
            "\u001b[2K    Found existing installation: tzdata 2025.2\n",
            "\u001b[2K    Uninstalling tzdata-2025.2:\n",
            "\u001b[2K      Successfully uninstalled tzdata-2025.2\n",
            "\u001b[2K  Attempting uninstall: tqdm\n",
            "\u001b[2K    Found existing installation: tqdm 4.67.1\n",
            "\u001b[2K    Uninstalling tqdm-4.67.1:\n",
            "\u001b[2K      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[2K  Attempting uninstall: threadpoolctl\n",
            "\u001b[2K    Found existing installation: threadpoolctl 3.6.0\n",
            "\u001b[2K    Uninstalling threadpoolctl-3.6.0:\n",
            "\u001b[2K      Successfully uninstalled threadpoolctl-3.6.0\n",
            "\u001b[2K  Attempting uninstall: six\n",
            "\u001b[2K    Found existing installation: six 1.17.0\n",
            "\u001b[2K    Uninstalling six-1.17.0:\n",
            "\u001b[2K      Successfully uninstalled six-1.17.0\n",
            "\u001b[2K  Attempting uninstall: PyYAML\n",
            "\u001b[2K    Found existing installation: PyYAML 6.0.3\n",
            "\u001b[2K    Uninstalling PyYAML-6.0.3:\n",
            "\u001b[2K      Successfully uninstalled PyYAML-6.0.3\n",
            "\u001b[2K  Attempting uninstall: pyparsing\n",
            "\u001b[2K    Found existing installation: pyparsing 3.2.5\n",
            "\u001b[2K    Uninstalling pyparsing-3.2.5:\n",
            "\u001b[2K      Successfully uninstalled pyparsing-3.2.5\n",
            "\u001b[2K  Attempting uninstall: psutil\n",
            "\u001b[2K    Found existing installation: psutil 5.9.5\n",
            "\u001b[2K    Uninstalling psutil-5.9.5:\n",
            "\u001b[2K      Successfully uninstalled psutil-5.9.5\n",
            "\u001b[2K  Attempting uninstall: platformdirs\n",
            "\u001b[2K    Found existing installation: platformdirs 4.5.0\n",
            "\u001b[2K    Uninstalling platformdirs-4.5.0:\n",
            "\u001b[2K      Successfully uninstalled platformdirs-4.5.0\n",
            "\u001b[2K  Attempting uninstall: pillow\n",
            "\u001b[2K    Found existing installation: pillow 11.3.0\n",
            "\u001b[2K    Uninstalling pillow-11.3.0:\n",
            "\u001b[2K      Successfully uninstalled pillow-11.3.0\n",
            "\u001b[2K  Attempting uninstall: packaging\n",
            "\u001b[2K    Found existing installation: packaging 25.0\n",
            "\u001b[2K    Uninstalling packaging-25.0:\n",
            "\u001b[2K      Successfully uninstalled packaging-25.0\n",
            "\u001b[2K  Attempting uninstall: numpy\n",
            "\u001b[2K    Found existing installation: numpy 2.0.2\n",
            "\u001b[2K    Uninstalling numpy-2.0.2:\n",
            "\u001b[2K      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[2K  Attempting uninstall: MarkupSafe\n",
            "\u001b[2K    Found existing installation: MarkupSafe 3.0.3\n",
            "\u001b[2K    Uninstalling MarkupSafe-3.0.3:\n",
            "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3\n",
            "\u001b[2K  Attempting uninstall: kiwisolver\n",
            "\u001b[2K    Found existing installation: kiwisolver 1.4.9\n",
            "\u001b[2K    Uninstalling kiwisolver-1.4.9:\n",
            "\u001b[2K      Successfully uninstalled kiwisolver-1.4.9\n",
            "\u001b[2K  Attempting uninstall: joblib\n",
            "\u001b[2K    Found existing installation: joblib 1.5.2\n",
            "\u001b[2K    Uninstalling joblib-1.5.2:\n",
            "\u001b[2K      Successfully uninstalled joblib-1.5.2\n",
            "\u001b[2K  Attempting uninstall: idna\n",
            "\u001b[2K    Found existing installation: idna 3.11\n",
            "\u001b[2K    Uninstalling idna-3.11:\n",
            "\u001b[2K      Successfully uninstalled idna-3.11\n",
            "\u001b[2K  Attempting uninstall: fonttools\n",
            "\u001b[2K    Found existing installation: fonttools 4.60.1\n",
            "\u001b[2K    Uninstalling fonttools-4.60.1:\n",
            "\u001b[2K      Successfully uninstalled fonttools-4.60.1\n",
            "\u001b[2K  Attempting uninstall: decorator\n",
            "\u001b[2K    Found existing installation: decorator 4.4.2\n",
            "\u001b[2K    Uninstalling decorator-4.4.2:\n",
            "\u001b[2K      Successfully uninstalled decorator-4.4.2\n",
            "\u001b[2K  Attempting uninstall: cycler\n",
            "\u001b[2K    Found existing installation: cycler 0.12.1\n",
            "\u001b[2K    Uninstalling cycler-0.12.1:\n",
            "\u001b[2K      Successfully uninstalled cycler-0.12.1\n",
            "\u001b[2K  Attempting uninstall: charset_normalizer\n",
            "\u001b[2K    Found existing installation: charset-normalizer 3.4.4\n",
            "\u001b[2K    Uninstalling charset-normalizer-3.4.4:\n",
            "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.4\n",
            "\u001b[2K  Attempting uninstall: certifi\n",
            "\u001b[2K    Found existing installation: certifi 2025.11.12\n",
            "\u001b[2K    Uninstalling certifi-2025.11.12:\n",
            "\u001b[2K      Successfully uninstalled certifi-2025.11.12\n",
            "\u001b[2K  Attempting uninstall: scipy\n",
            "\u001b[2K    Found existing installation: scipy 1.16.3\n",
            "\u001b[2K    Uninstalling scipy-1.16.3:\n",
            "\u001b[2K      Successfully uninstalled scipy-1.16.3\n",
            "\u001b[2K  Attempting uninstall: requests\n",
            "\u001b[2K    Found existing installation: requests 2.32.4\n",
            "\u001b[2K    Uninstalling requests-2.32.4:\n",
            "\u001b[2K      Successfully uninstalled requests-2.32.4\n",
            "\u001b[2K  Attempting uninstall: python-dateutil\n",
            "\u001b[2K    Found existing installation: python-dateutil 2.9.0.post0\n",
            "\u001b[2K    Uninstalling python-dateutil-2.9.0.post0:\n",
            "\u001b[2K      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "\u001b[2K  Attempting uninstall: lazy-loader\n",
            "\u001b[2K    Found existing installation: lazy_loader 0.4\n",
            "\u001b[2K    Uninstalling lazy_loader-0.4:\n",
            "\u001b[2K      Successfully uninstalled lazy_loader-0.4\n",
            "\u001b[2K  Attempting uninstall: jinja2\n",
            "\u001b[2K    Found existing installation: Jinja2 3.1.6\n",
            "\u001b[2K    Uninstalling Jinja2-3.1.6:\n",
            "\u001b[2K      Successfully uninstalled Jinja2-3.1.6\n",
            "\u001b[2K  Attempting uninstall: h5py\n",
            "\u001b[2K    Found existing installation: h5py 3.15.1\n",
            "\u001b[2K    Uninstalling h5py-3.15.1:\n",
            "\u001b[2K      Successfully uninstalled h5py-3.15.1\n",
            "\u001b[2K  Attempting uninstall: contourpy\n",
            "\u001b[2K    Found existing installation: contourpy 1.3.3\n",
            "\u001b[2K    Uninstalling contourpy-1.3.3:\n",
            "\u001b[2K      Successfully uninstalled contourpy-1.3.3\n",
            "\u001b[2K  Attempting uninstall: scikit-learn\n",
            "\u001b[2K    Found existing installation: scikit-learn 1.6.1\n",
            "\u001b[2K    Uninstalling scikit-learn-1.6.1:\n",
            "\u001b[2K      Successfully uninstalled scikit-learn-1.6.1\n",
            "\u001b[2K  Attempting uninstall: pooch\n",
            "\u001b[2K    Found existing installation: pooch 1.8.2\n",
            "\u001b[2K    Uninstalling pooch-1.8.2:\n",
            "\u001b[2K      Successfully uninstalled pooch-1.8.2\n",
            "\u001b[2K  Attempting uninstall: pandas\n",
            "\u001b[2K    Found existing installation: pandas 2.2.2\n",
            "\u001b[2K    Uninstalling pandas-2.2.2:\n",
            "\u001b[2K      Successfully uninstalled pandas-2.2.2\n",
            "\u001b[2K  Attempting uninstall: matplotlib\n",
            "\u001b[2K    Found existing installation: matplotlib 3.10.0\n",
            "\u001b[2K    Uninstalling matplotlib-3.10.0:\n",
            "\u001b[2K      Successfully uninstalled matplotlib-3.10.0\n",
            "\u001b[2K  Attempting uninstall: seaborn\n",
            "\u001b[2K    Found existing installation: seaborn 0.13.2\n",
            "\u001b[2K    Uninstalling seaborn-0.13.2:\n",
            "\u001b[2K      Successfully uninstalled seaborn-0.13.2\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/42\u001b[0m [moabb]\n",
            "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "moviepy 1.0.3 requires decorator<5.0,>=4.0.2, but you have decorator 5.2.1 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.50.0 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.3 PyYAML-6.0.3 certifi-2025.11.12 charset_normalizer-3.4.4 contourpy-1.3.3 coverage-7.12.0 cycler-0.12.1 decorator-5.2.1 edfio-0.4.11 edflib-python-1.0.8 fonttools-4.61.0 h5py-3.15.1 idna-3.11 jinja2-3.1.6 joblib-1.5.2 kiwisolver-1.4.9 lazy-loader-0.4 matplotlib-3.9.2 memory-profiler-0.61.0 mne-1.10.2 mne-bids-0.17.0 moabb-1.2.0 numpy-1.26.4 packaging-25.0 pandas-2.2.2 pillow-12.0.0 platformdirs-4.5.1 pooch-1.8.2 psutil-7.1.3 pyparsing-3.2.5 pyriemann-0.7 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.5 scikit-learn-1.5.2 scipy-1.13.1 seaborn-0.12.2 six-1.17.0 threadpoolctl-3.6.0 tqdm-4.67.1 tzdata-2025.2 urllib3-1.26.20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "cycler",
                  "dateutil",
                  "decorator",
                  "kiwisolver",
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "packaging",
                  "platformdirs",
                  "psutil",
                  "pyparsing",
                  "six"
                ]
              },
              "id": "9bf6262d22534848bca51c07d225e5e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (80.9.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --no-cache-dir pip setuptools wheel\n",
        "\n",
        "# core libs\n",
        "%pip install --force-reinstall --no-cache-dir \\\n",
        "  \"numpy==1.26.4\" \"pandas==2.2.2\" \"scipy==1.13.1\" \\\n",
        "  \"mne==1.10.2\" \"pyriemann==0.7\" \"moabb==1.2.0\" \\\n",
        "  \"scikit-learn==1.5.2\" \"matplotlib==3.9.2\"\n",
        "\n",
        "# PyTorch GPU\n",
        "%pip install --no-cache-dir --index-url https://download.pytorch.org/whl/cu121 torch torchvision torchaudio\n",
        "\n",
        "%pip install --no-cache-dir tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import libs"
      ],
      "metadata": {
        "id": "lxzKEM2EMZh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Config for my drive & MNE/MOABB\n",
        "from google.colab import drive\n",
        "import mne\n",
        "from moabb.datasets import BI2013a\n",
        "from moabb.paradigms import P300\n",
        "\n",
        "# Signal processing\n",
        "from scipy.signal import butter, sosfiltfilt, decimate\n",
        "\n",
        "# PyTorch (no nn/optim)\n",
        "import torch\n",
        "from torch import Tensor\n",
        "\n",
        "# Split & metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score, balanced_accuracy_score,\n",
        "    roc_auc_score, confusion_matrix,\n",
        ")"
      ],
      "metadata": {
        "id": "h28v8bBPMY_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuwBH3N8rojA"
      },
      "source": [
        "### Config to save dataset on my drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPoiuabNVueh",
        "outputId": "e8fa7fbe-7454-4505-c967-71c3db30dceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Attempting to create new mne-python configuration file:\n",
            "/root/.mne/mne-python.json\n",
            "Could not read the /root/.mne/mne-python.json json file during the writing. Assuming it is empty. Got: Expecting value: line 1 column 1 (char 0)\n",
            "ENV MNE_DATA: /content/drive/MyDrive/mne_data\n",
            "mne.get_config('MNE_DATA'): /content/drive/MyDrive/mne_data\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3433513575.py:15: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_PATH\"\n",
            "  mne.set_config(\"MNE_DATASETS_PATH\", DATA_DIR, set_env=True)\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_DIR = \"/content/drive/MyDrive/mne_data\"\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "os.environ[\"MNE_DATA\"] = DATA_DIR\n",
        "os.environ[\"MNE_DATASETS_PATH\"] = DATA_DIR\n",
        "os.environ[\"MOABB_DATA_PATH\"] = DATA_DIR\n",
        "os.environ[\"MOABB_DOWNLOAD_DIR\"] = DATA_DIR\n",
        "os.environ[\"MOABB_CACHE_DIR\"] = DATA_DIR\n",
        "\n",
        "mne.set_config(\"MNE_DATA\", DATA_DIR, set_env=True)\n",
        "mne.set_config(\"MNE_DATASETS_PATH\", DATA_DIR, set_env=True)\n",
        "\n",
        "print(\"ENV MNE_DATA:\", os.getenv(\"MNE_DATA\"))\n",
        "print(\"mne.get_config('MNE_DATA'):\", mne.get_config(\"MNE_DATA\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Symlink:  /root/mne_data -> Drive\n",
        "import os, subprocess, shutil, pathlib\n",
        "\n",
        "if os.path.islink(\"/root/mne_data\") or os.path.exists(\"/root/mne_data\"):\n",
        "    shutil.rmtree(\"/root/mne_data\", ignore_errors=True)\n",
        "\n",
        "#  symlink\n",
        "pathlib.Path(\"/root\").mkdir(parents=True, exist_ok=True)\n",
        "subprocess.run([\"ln\", \"-s\", DATA_DIR, \"/root/mne_data\"], check=True)\n",
        "\n",
        "print(\"Symlink OK:\", os.path.islink(\"/root/mne_data\"), \"->\", os.readlink(\"/root/mne_data\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd8GyqzuI2U3",
        "outputId": "fd941d9b-4f09-41f4-fc8c-ac07922a20d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Symlink OK: True -> /content/drive/MyDrive/mne_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo9DN7uyudgN"
      },
      "source": [
        "## Install the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VizFAfmV1iL",
        "outputId": "dbdaff08-4999-41f0-c255-26838af68f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/download.py:56: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BRAININVADERS2013_PATH\"\n",
            "  set_config(key, get_config(\"MNE_DATA\"))\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 192 events (all good), 0 – 1 s (baseline off), ~12.0 MiB, data loaded,\n",
            " 'Target': 32\n",
            " 'NonTarget': 160>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 156 events (all good), 0 – 1 s (baseline off), ~9.8 MiB, data loaded,\n",
            " 'Target': 26\n",
            " 'NonTarget': 130>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 168 events (all good), 0 – 1 s (baseline off), ~10.5 MiB, data loaded,\n",
            " 'Target': 28\n",
            " 'NonTarget': 140>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 168 events (all good), 0 – 1 s (baseline off), ~10.5 MiB, data loaded,\n",
            " 'Target': 28\n",
            " 'NonTarget': 140>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 156 events (all good), 0 – 1 s (baseline off), ~9.8 MiB, data loaded,\n",
            " 'Target': 26\n",
            " 'NonTarget': 130>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 300 events (all good), 0 – 1 s (baseline off), ~18.8 MiB, data loaded,\n",
            " 'Target': 50\n",
            " 'NonTarget': 250>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 144 events (all good), 0 – 1 s (baseline off), ~9.0 MiB, data loaded,\n",
            " 'Target': 24\n",
            " 'NonTarget': 120>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 264 events (all good), 0 – 1 s (baseline off), ~16.6 MiB, data loaded,\n",
            " 'Target': 44\n",
            " 'NonTarget': 220>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 168 events (all good), 0 – 1 s (baseline off), ~10.5 MiB, data loaded,\n",
            " 'Target': 28\n",
            " 'NonTarget': 140>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 144 events (all good), 0 – 1 s (baseline off), ~9.0 MiB, data loaded,\n",
            " 'Target': 24\n",
            " 'NonTarget': 120>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 276 events (all good), 0 – 1 s (baseline off), ~17.3 MiB, data loaded,\n",
            " 'Target': 46\n",
            " 'NonTarget': 230>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 192 events (all good), 0 – 1 s (baseline off), ~12.0 MiB, data loaded,\n",
            " 'Target': 32\n",
            " 'NonTarget': 160>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 360 events (all good), 0 – 1 s (baseline off), ~22.6 MiB, data loaded,\n",
            " 'Target': 60\n",
            " 'NonTarget': 300>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 156 events (all good), 0 – 1 s (baseline off), ~9.8 MiB, data loaded,\n",
            " 'Target': 26\n",
            " 'NonTarget': 130>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 168 events (all good), 0 – 1 s (baseline off), ~10.5 MiB, data loaded,\n",
            " 'Target': 28\n",
            " 'NonTarget': 140>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 276 events (all good), 0 – 1 s (baseline off), ~17.3 MiB, data loaded,\n",
            " 'Target': 46\n",
            " 'NonTarget': 230>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 504 events (all good), 0 – 1 s (baseline off), ~31.6 MiB, data loaded,\n",
            " 'Target': 84\n",
            " 'NonTarget': 420>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 276 events (all good), 0 – 1 s (baseline off), ~17.3 MiB, data loaded,\n",
            " 'Target': 46\n",
            " 'NonTarget': 230>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 240 events (all good), 0 – 1 s (baseline off), ~15.1 MiB, data loaded,\n",
            " 'Target': 40\n",
            " 'NonTarget': 200>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 168 events (all good), 0 – 1 s (baseline off), ~10.5 MiB, data loaded,\n",
            " 'Target': 28\n",
            " 'NonTarget': 140>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 192 events (all good), 0 – 1 s (baseline off), ~12.0 MiB, data loaded,\n",
            " 'Target': 32\n",
            " 'NonTarget': 160>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 216 events (all good), 0 – 1 s (baseline off), ~13.5 MiB, data loaded,\n",
            " 'Target': 36\n",
            " 'NonTarget': 180>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 288 events (all good), 0 – 1 s (baseline off), ~18.1 MiB, data loaded,\n",
            " 'Target': 48\n",
            " 'NonTarget': 240>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 324 events (all good), 0 – 1 s (baseline off), ~20.3 MiB, data loaded,\n",
            " 'Target': 54\n",
            " 'NonTarget': 270>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 216 events (all good), 0 – 1 s (baseline off), ~13.5 MiB, data loaded,\n",
            " 'Target': 36\n",
            " 'NonTarget': 180>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 240 events (all good), 0 – 1 s (baseline off), ~15.1 MiB, data loaded,\n",
            " 'Target': 40\n",
            " 'NonTarget': 200>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 264 events (all good), 0 – 1 s (baseline off), ~16.6 MiB, data loaded,\n",
            " 'Target': 44\n",
            " 'NonTarget': 220>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 336 events (all good), 0 – 1 s (baseline off), ~21.1 MiB, data loaded,\n",
            " 'Target': 56\n",
            " 'NonTarget': 280>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 228 events (all good), 0 – 1 s (baseline off), ~14.3 MiB, data loaded,\n",
            " 'Target': 38\n",
            " 'NonTarget': 190>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 276 events (all good), 0 – 1 s (baseline off), ~17.3 MiB, data loaded,\n",
            " 'Target': 46\n",
            " 'NonTarget': 230>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 300 events (all good), 0 – 1 s (baseline off), ~18.8 MiB, data loaded,\n",
            " 'Target': 50\n",
            " 'NonTarget': 250>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 192 events (all good), 0 – 1 s (baseline off), ~12.0 MiB, data loaded,\n",
            " 'Target': 32\n",
            " 'NonTarget': 160>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 216 events (all good), 0 – 1 s (baseline off), ~13.5 MiB, data loaded,\n",
            " 'Target': 36\n",
            " 'NonTarget': 180>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 336 events (all good), 0 – 1 s (baseline off), ~21.1 MiB, data loaded,\n",
            " 'Target': 56\n",
            " 'NonTarget': 280>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 156 events (all good), 0 – 1 s (baseline off), ~9.8 MiB, data loaded,\n",
            " 'Target': 26\n",
            " 'NonTarget': 130>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 300 events (all good), 0 – 1 s (baseline off), ~18.8 MiB, data loaded,\n",
            " 'Target': 50\n",
            " 'NonTarget': 250>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 264 events (all good), 0 – 1 s (baseline off), ~16.6 MiB, data loaded,\n",
            " 'Target': 44\n",
            " 'NonTarget': 220>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 288 events (all good), 0 – 1 s (baseline off), ~18.1 MiB, data loaded,\n",
            " 'Target': 48\n",
            " 'NonTarget': 240>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 192 events (all good), 0 – 1 s (baseline off), ~12.0 MiB, data loaded,\n",
            " 'Target': 32\n",
            " 'NonTarget': 160>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 276 events (all good), 0 – 1 s (baseline off), ~17.3 MiB, data loaded,\n",
            " 'Target': 46\n",
            " 'NonTarget': 230>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 228 events (all good), 0 – 1 s (baseline off), ~14.3 MiB, data loaded,\n",
            " 'Target': 38\n",
            " 'NonTarget': 190>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 216 events (all good), 0 – 1 s (baseline off), ~13.5 MiB, data loaded,\n",
            " 'Target': 36\n",
            " 'NonTarget': 180>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 216 events (all good), 0 – 1 s (baseline off), ~13.5 MiB, data loaded,\n",
            " 'Target': 36\n",
            " 'NonTarget': 180>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 252 events (all good), 0 – 1 s (baseline off), ~15.8 MiB, data loaded,\n",
            " 'Target': 42\n",
            " 'NonTarget': 210>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 252 events (all good), 0 – 1 s (baseline off), ~15.8 MiB, data loaded,\n",
            " 'Target': 42\n",
            " 'NonTarget': 210>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 228 events (all good), 0 – 1 s (baseline off), ~14.3 MiB, data loaded,\n",
            " 'Target': 38\n",
            " 'NonTarget': 190>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 384 events (all good), 0 – 1 s (baseline off), ~24.1 MiB, data loaded,\n",
            " 'Target': 64\n",
            " 'NonTarget': 320>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 180 events (all good), 0 – 1 s (baseline off), ~11.3 MiB, data loaded,\n",
            " 'Target': 30\n",
            " 'NonTarget': 150>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 228 events (all good), 0 – 1 s (baseline off), ~14.3 MiB, data loaded,\n",
            " 'Target': 38\n",
            " 'NonTarget': 190>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 204 events (all good), 0 – 1 s (baseline off), ~12.8 MiB, data loaded,\n",
            " 'Target': 34\n",
            " 'NonTarget': 170>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 300 events (all good), 0 – 1 s (baseline off), ~18.8 MiB, data loaded,\n",
            " 'Target': 50\n",
            " 'NonTarget': 250>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 228 events (all good), 0 – 1 s (baseline off), ~14.3 MiB, data loaded,\n",
            " 'Target': 38\n",
            " 'NonTarget': 190>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 480 events (all good), 0 – 1 s (baseline off), ~30.1 MiB, data loaded,\n",
            " 'Target': 80\n",
            " 'NonTarget': 400>\n",
            "  warn(f\"warnEpochs {epochs}\")\n",
            "/usr/local/lib/python3.12/dist-packages/moabb/datasets/preprocessing.py:278: UserWarning: warnEpochs <Epochs | 300 events (all good), 0 – 1 s (baseline off), ~18.8 MiB, data loaded,\n",
            " 'Target': 50\n",
            " 'NonTarget': 250>\n",
            "  warn(f\"warnEpochs {epochs}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X shape: (45312, 16, 513)\n",
            "y sample: ['Target' 'NonTarget' 'NonTarget' 'NonTarget' 'NonTarget' 'NonTarget'\n",
            " 'NonTarget' 'Target' 'NonTarget' 'NonTarget']\n",
            "   subject session run\n",
            "0        1       0   0\n",
            "1        1       0   0\n",
            "2        1       0   0\n",
            "3        1       0   0\n",
            "4        1       0   0\n",
            "Label counts: {'NonTarget': 37760, 'Target': 7552}\n"
          ]
        }
      ],
      "source": [
        "SUBJECTS = [1, 2, 3, 4]\n",
        "ds = BI2013a(NonAdaptive=True, Adaptive=True, Training=True, Online=True)\n",
        "paradigm = P300(resample=None)\n",
        "\n",
        "# get data from drive, download only data that is not yet available\n",
        "X, y_str, meta = paradigm.get_data(dataset=ds, subjects=SUBJECTS)\n",
        "\n",
        "print(\"X shape:\", X.shape)           # (N_trials, N_channels, N_times)\n",
        "print(\"y sample:\", y_str[:10])\n",
        "print(meta.head())\n",
        "print(\"Label counts:\", pd.Series(y_str).value_counts().to_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RImdKTD-wTgH"
      },
      "source": [
        "X (N_trials, N_channels, N_times) =  (45312, 16, 513)\n",
        "\n",
        "* N_trials = 45 312: number of trials/epoch (train ~ epoch)\n",
        "\n",
        "* N_channels = 16: the number of EEG electrodes used to conduct measurement\n",
        "\n",
        "* N_times = 513: sample number of times in an epoch (total time = fs * N_times)\n",
        "\n",
        "y ('NonTarget', 'Target') = (37760, 7552)\n",
        "\n",
        "* each trial has a label y\n",
        "\n",
        "* Target -> + has P300\n",
        "\n",
        "* Non-Target -> none P300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntvTXsVU1OUE"
      },
      "source": [
        "## Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guard: make sure there are  X, y_str, meta"
      ],
      "metadata": {
        "id": "dnWxG_blJp5j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EWZd57dTEuHi"
      },
      "outputs": [],
      "source": [
        "assert 'X' in globals() and 'y_str' in globals() and 'meta' in globals(), \\\n",
        "    \"Need to run the previous block (create X, y_str, meta).\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of parameters"
      ],
      "metadata": {
        "id": "6k7bMju1LoEC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "afhdawLNFlwl"
      },
      "outputs": [],
      "source": [
        "# ==== fs, tmin (iloc[0] - first sample time of epoch) ====\n",
        "fs = float(meta[\"sfreq\"].iloc[0]) if \"sfreq\" in meta.columns else 256.0\n",
        "tmin = float(meta[\"tmin\"].iloc[0]) if \"tmin\" in meta.columns else -0.2\n",
        "\n",
        "# ==== parameters pipeline ====\n",
        "lo, hi, order = 0.1, 15.0, 4\n",
        "target_fs = 128                     # decimate\n",
        "win = (0.30, 0.60)                  # Windowing EEG\n",
        "base = (-0.2, 0.0)                  # baseline\n",
        "n_bins = 6                          # bin feature\n",
        "BATCH = 64                          # batch per trial\n",
        "\n",
        "# ==== Prepare time Index once ====\n",
        "N, C, T = X.shape\n",
        "times = tmin + np.arange(T) / fs\n",
        "base_mask = (times >= base[0]) & (times <= base[1])\n",
        "win_mask  = (times >= win[0])  & (times <= win[1])\n",
        "\n",
        "# ==== filters ====\n",
        "nyq = fs * 0.5\n",
        "sos = butter(order, [lo/nyq, hi/nyq], btype='band', output='sos')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mean Bin Features"
      ],
      "metadata": {
        "id": "1DYm9jXZP-XW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fgDAPSscFyXG"
      },
      "outputs": [],
      "source": [
        "def feats_from_window(Xw, n_bins=6):\n",
        "    # Xw: (b, C, Tw) float32\n",
        "    bsz, Cc, Tw = Xw.shape\n",
        "    edges = np.linspace(0, Tw, n_bins+1, dtype=int)\n",
        "    F = np.empty((bsz, Cc, n_bins, 4), dtype=np.float32)\n",
        "    for i in range(n_bins):\n",
        "        s, e = edges[i], edges[i+1]\n",
        "        if e - s <= 0:\n",
        "            F[:, :, i, :] = 0.0\n",
        "            continue\n",
        "        seg = Xw[:, :, s:e]                           # (b,C,L)\n",
        "        m  = seg.mean(axis=2)\n",
        "        mx = seg.max(axis=2)\n",
        "        mn = seg.min(axis=2)\n",
        "        half = (e - s) // 2\n",
        "        if half == 0:\n",
        "            sl = np.zeros_like(m, dtype=np.float32)\n",
        "        else:\n",
        "            sl = seg[:, :, :half].mean(axis=2) - seg[:, :, half:].mean(axis=2)\n",
        "        F[:, :, i, 0] = m\n",
        "        F[:, :, i, 1] = mx\n",
        "        F[:, :, i, 2] = mn\n",
        "        F[:, :, i, 3] = sl\n",
        "    return F.reshape(bsz, Cc * n_bins * 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Window-length estimation, feature preallocation, and label encoding"
      ],
      "metadata": {
        "id": "w1gxGdslQld7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xDo_YIu9F1Sw"
      },
      "outputs": [],
      "source": [
        "Tw_est = int(win_mask.sum()) if not isinstance(win_mask, slice) else X.shape[2]\n",
        "X_feat = np.empty((N, C * n_bins * 4), dtype=np.float32)\n",
        "y = np.where(np.array(y_str) == \"Target\", 1.0, -1.0).astype(np.float32)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset preprocessing according to batch"
      ],
      "metadata": {
        "id": "6wf_veLzQ7u6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCWcHTdzd53L",
        "outputId": "01f32c27-8337-4761-b55c-ef243ffcfeee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decimated to fs=128.0 Hz (ratio=2) | shape batch: (64, 16, 39)\n",
            "Features: (45312, 384)  | Pos%: 0.16666666666666666\n"
          ]
        }
      ],
      "source": [
        "fs_eff = fs   # keep the fs fixed for the pipeline\n",
        "for s in range(0, N, BATCH):\n",
        "    e = min(N, s + BATCH)\n",
        "    # get batch and press float32 (reduce 1/2 RAM)\n",
        "    xb = np.asarray(X[s:e], dtype=np.float32, order='C')   # (b,C,T)\n",
        "\n",
        "    # 1) Band-pass (sosfiltfilt per trial)\n",
        "    for i in range(xb.shape[0]):\n",
        "        xb[i] = sosfiltfilt(sos, xb[i], axis=1)\n",
        "\n",
        "    # 2) Baseline correction\n",
        "    if isinstance(base_mask, np.ndarray) and base_mask.any():\n",
        "        base_mean = xb[:, :, base_mask].mean(axis=2, keepdims=True)\n",
        "        xb -= base_mean\n",
        "\n",
        "    # 3) Window eeg\n",
        "    if isinstance(win_mask, np.ndarray):\n",
        "        xw = xb[:, :, win_mask].copy()\n",
        "    else:\n",
        "        xw = xb\n",
        "\n",
        "    # 4) Decimate to target_fs\n",
        "    fs_dec = fs_eff\n",
        "    if int(fs_eff) != target_fs:\n",
        "        ratio = int(round(fs_eff / target_fs))\n",
        "        if ratio >= 2 and abs(fs_eff/ratio - target_fs) < 1e-6:\n",
        "            xwd = []\n",
        "            for i in range(xw.shape[0]):\n",
        "                xi = decimate(xw[i], ratio, axis=1, ftype='fir', zero_phase=True).astype(np.float32, copy=False)\n",
        "                xwd.append(xi)\n",
        "            xw = np.stack(xwd, axis=0)   # (batch, C, Tw//ratio)\n",
        "            del xwd\n",
        "            fs_dec = fs_eff / ratio\n",
        "            if s == 0:\n",
        "                print(f\"Decimated to fs={fs_dec} Hz (ratio={ratio}) | shape batch:\", xw.shape)\n",
        "        else:\n",
        "            if s == 0:\n",
        "                print(\"Ignore decimate because fs does not divide logically.\")\n",
        "\n",
        "    # 5) Extract feature per bin\n",
        "    X_feat[s:e] = feats_from_window(xw, n_bins=n_bins)\n",
        "\n",
        "    # clean\n",
        "    del xb, xw\n",
        "    gc.collect()\n",
        "\n",
        "print(\"Features:\", X_feat.shape, \" | Pos%:\", float((y==1).mean()))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHyeVTy2sZ2Q"
      },
      "source": [
        "## Model SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RqptfEvRjdHH"
      },
      "outputs": [],
      "source": [
        "class LinearSVMTorch:\n",
        "    def __init__(self, lr=1e-3, C=1.0, reg=1e-4, batch_size=128,\n",
        "                 n_epochs=10, shuffle=True, random_state=123, device=None):\n",
        "        # hyper-params\n",
        "        self.lr = lr\n",
        "        self.C = C              # coefficient for hinge loss\n",
        "        self.reg = reg          # L2 weight (same role as in NumPy version)\n",
        "        self.batch_size = batch_size\n",
        "        self.n_epochs = n_epochs\n",
        "        self.shuffle = shuffle\n",
        "        self.random_state = random_state\n",
        "        # runtime\n",
        "        self.device = device or (torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n",
        "        # parameters (initialized in fit)\n",
        "        self.W = None  # (D, 1) tensor, requires_grad=True\n",
        "        self.b = None  # () tensor, requires_grad=True\n",
        "\n",
        "    # --- helpers ---\n",
        "    @staticmethod\n",
        "    def _to_tensor(x, device):\n",
        "        \"\"\"Convert numpy/torch to torch.float32 on device.\"\"\"\n",
        "        if isinstance(x, Tensor):\n",
        "            return x.to(device=device, dtype=torch.float32, non_blocking=True)\n",
        "        return torch.as_tensor(x, dtype=torch.float32, device=device)\n",
        "\n",
        "    def _batch_iter(self, X: torch.Tensor, y: torch.Tensor):\n",
        "      \"\"\"Yield mini-batches with optional shuffling (pure torch).\"\"\"\n",
        "      N = X.shape[0]\n",
        "      if self.shuffle:\n",
        "          # make generator on CPU, sample on CPU, then move to device\n",
        "          g = torch.Generator(device=\"cpu\")\n",
        "          g.manual_seed(self.random_state)\n",
        "          idx = torch.randperm(N, generator=g)           # CPU tensor\n",
        "          idx = idx.to(self.device, non_blocking=True)   # move to GPU/CPU target\n",
        "      else:\n",
        "          idx = torch.arange(N, device=self.device)\n",
        "      for s in range(0, N, self.batch_size):\n",
        "          j = idx[s:s + self.batch_size]\n",
        "          yield X[j], y[j]\n",
        "\n",
        "\n",
        "    # --- api ---\n",
        "    def fit(self, X, y, X_val=None, y_val=None, verbose=True):\n",
        "        \"\"\"\n",
        "        X: (N, D) float32/np, y: (N,) in {-1,+1}\n",
        "        \"\"\"\n",
        "        torch.manual_seed(self.random_state)\n",
        "\n",
        "        X = self._to_tensor(X, self.device)  # (N, D)\n",
        "        y = self._to_tensor(y, self.device)  # (N,)\n",
        "\n",
        "        N, D = X.shape\n",
        "        # init params (zeros like NumPy impl)\n",
        "        self.W = torch.zeros(D, 1, device=self.device, dtype=torch.float32, requires_grad=True)\n",
        "        self.b = torch.zeros(1, device=self.device, dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "        # (optional) validation tensors\n",
        "        Xv = self._to_tensor(X_val, self.device) if X_val is not None else None\n",
        "        yv = self._to_tensor(y_val, self.device) if y_val is not None else None\n",
        "\n",
        "        for epoch in range(1, self.n_epochs + 1):\n",
        "            total_loss = 0.0\n",
        "            seen = 0\n",
        "\n",
        "            for Xb, yb in self._batch_iter(X, y):\n",
        "                # ----- forward -----\n",
        "                # scores: (B,)  = Xb @ W + b\n",
        "                scores = (Xb @ self.W).squeeze(-1) + self.b  # (B,)\n",
        "                # margins = 1 - y * score\n",
        "                margins = 1.0 - yb * scores                  # (B,)\n",
        "                # hinge part (mean over violations)\n",
        "                hinge = torch.clamp(margins, min=0.0)        # (B,)\n",
        "                hinge_loss = hinge.mean()\n",
        "                # L2 on weights (same as 0.5 * reg * ||w||^2)\n",
        "                l2 = 0.5 * self.reg * (self.W.square().sum())\n",
        "                # total loss\n",
        "                loss = self.C * hinge_loss + l2\n",
        "\n",
        "                # ----- backward -----\n",
        "                # zero grads\n",
        "                if self.W.grad is not None: self.W.grad.zero_()\n",
        "                if self.b.grad is not None: self.b.grad.zero_()\n",
        "                loss.backward()\n",
        "\n",
        "                # ----- manual SGD update -----\n",
        "                with torch.no_grad():\n",
        "                    self.W -= self.lr * self.W.grad\n",
        "                    self.b -= self.lr * self.b.grad\n",
        "\n",
        "                total_loss += float(loss.item()) * Xb.shape[0]\n",
        "                seen += Xb.shape[0]\n",
        "\n",
        "            avg_loss = total_loss / max(seen, 1)\n",
        "\n",
        "            if verbose:\n",
        "                if Xv is not None and yv is not None:\n",
        "                    val_pred = self.predict(Xv)  # returns torch tensor {-1,+1}\n",
        "                    val_acc = (val_pred == yv).float().mean().item()\n",
        "                    print(f\"Epoch {epoch:02d}: loss={avg_loss:.5f} | val_acc={val_acc:.4f}\")\n",
        "                else:\n",
        "                    print(f\"Epoch {epoch:02d}: loss={avg_loss:.5f}\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    @torch.no_grad() # turn off autograd in this function -> dont use RAM\n",
        "    def decision_function(self, X):\n",
        "        \"\"\"Return raw scores (no threshold). Accepts numpy or tensor. Output: torch tensor (N,).\"\"\"\n",
        "        X = self._to_tensor(X, self.device)\n",
        "        scores = (X @ self.W).squeeze(-1) + self.b\n",
        "        return scores\n",
        "\n",
        "    @torch.no_grad() # turn off autograd in this function -> dont use RAM\n",
        "    def predict(self, X, thr: float = 0.0):\n",
        "        \"\"\"Return labels in {-1,+1} on the SAME device as model/input.\"\"\"\n",
        "        s = self.decision_function(X)  # stays on self.device\n",
        "        return torch.where(\n",
        "            s >= thr,\n",
        "            torch.tensor(1.0, device=s.device),\n",
        "            torch.tensor(-1.0, device=s.device),\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test"
      ],
      "metadata": {
        "id": "MOfjjEPpT9b2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXwIh7ccsTsL"
      },
      "source": [
        "Dataset split and standardization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAVbWuUvjby3",
        "outputId": "a2e32c7e-a400-4b4e-d321-d8c7c4fc705d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Val/Test: (31718, 384) (6797, 384) (6797, 384)\n"
          ]
        }
      ],
      "source": [
        "X_tr, X_tmp, y_tr, y_tmp = train_test_split(\n",
        "    X_feat, y, test_size=0.30, random_state=42, stratify=y\n",
        ")\n",
        "X_va, X_te, y_va, y_te = train_test_split(\n",
        "    X_tmp, y_tmp, test_size=0.50, random_state=42, stratify=y_tmp\n",
        ")\n",
        "\n",
        "print(\"Train/Val/Test:\", X_tr.shape, X_va.shape, X_te.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom standardization function"
      ],
      "metadata": {
        "id": "QOEYWzvxTMcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StandardScalerLite:\n",
        "    def fit(self, X):\n",
        "        self.mean_ = X.mean(axis=0, keepdims=True)\n",
        "        self.std_  = X.std(axis=0, keepdims=True) + 1e-8\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        return (X - self.mean_) / self.std_\n",
        "    def fit_transform(self, X):\n",
        "        return self.fit(X).transform(X)\n",
        "\n",
        "scaler = StandardScalerLite()\n",
        "X_tr = scaler.fit_transform(X_tr)   # fit on train\n",
        "X_va = scaler.transform(X_va)       # apply to val\n",
        "X_te = scaler.transform(X_te)       # apply to test"
      ],
      "metadata": {
        "id": "4H_xBEu8Ig6R"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxmyXsvzsdMz"
      },
      "source": [
        "Training & selecting threshold, metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm = LinearSVMTorch(lr=2e-3, C=1.0, reg=1e-4, batch_size=256, n_epochs=12,\n",
        "                     shuffle=True, random_state=42)\n",
        "svm.fit(X_tr, y_tr, X_val=X_va, y_val=y_va, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eU_tKVf5JM3A",
        "outputId": "ac8a70b9-cfa4-4303-ee0a-c1a4303d2ff8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01: loss=0.92860 | val_acc=0.7389\n",
            "Epoch 02: loss=0.79448 | val_acc=0.7662\n",
            "Epoch 03: loss=0.68679 | val_acc=0.8095\n",
            "Epoch 04: loss=0.59252 | val_acc=0.8339\n",
            "Epoch 05: loss=0.50529 | val_acc=0.8345\n",
            "Epoch 06: loss=0.42765 | val_acc=0.8333\n",
            "Epoch 07: loss=0.37007 | val_acc=0.8333\n",
            "Epoch 08: loss=0.34517 | val_acc=0.8333\n",
            "Epoch 09: loss=0.33876 | val_acc=0.8333\n",
            "Epoch 10: loss=0.33692 | val_acc=0.8333\n",
            "Epoch 11: loss=0.33647 | val_acc=0.8333\n",
            "Epoch 12: loss=0.33606 | val_acc=0.8333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.LinearSVMTorch at 0x7e89143ff1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decision_function returns torch tensor; convert to numpy for sklearn\n",
        "scores_va = svm.decision_function(X_va).cpu().numpy()\n",
        "\n",
        "ths = np.quantile(scores_va, np.linspace(0.05, 0.95, 19))\n",
        "best_th, best_f1 = 0.0, -1.0\n",
        "for th in ths:\n",
        "    y_hat = np.where(scores_va >= th, 1.0, -1.0)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(\n",
        "        y_va, y_hat, average='binary', zero_division=0, pos_label=1.0\n",
        "    )\n",
        "    if f1 > best_f1:\n",
        "        best_f1, best_th = f1, th\n",
        "\n",
        "print(f\"Best threshold on VAL: {best_th:.6f} (F1={best_f1:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czfaJGxJJSUN",
        "outputId": "b0adf25b-5c4b-471c-bbac-70b5ddf44276"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold on VAL: -1.005146 (F1=0.4477)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1qtD-LhfVms",
        "outputId": "2ff7a9f4-7f10-4af7-c226-682c235b23c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==== TEST METRICS ====\n",
            "Threshold used   : -1.005146\n",
            "Accuracy         : 0.7449\n",
            "Balanced Acc     : 0.6937\n",
            "Precision/Recall/F1: 0.3497/ 0.6169/ 0.4464\n",
            "ROC-AUC          : 0.7645\n"
          ]
        }
      ],
      "source": [
        "scores_te = svm.decision_function(X_te).cpu().numpy()\n",
        "y_pred = np.where(scores_te >= best_th, 1.0, -1.0)\n",
        "\n",
        "# For some metrics we use {0,1}\n",
        "y_te01 = (y_te == 1.0).astype(int)\n",
        "y_pred01 = (y_pred == 1.0).astype(int)\n",
        "\n",
        "acc  = accuracy_score(y_te, y_pred)\n",
        "bacc = balanced_accuracy_score(y_te01, y_pred01)\n",
        "prec, rec, f1, _ = precision_recall_fscore_support(y_te, y_pred, average='binary',\n",
        "                                                   zero_division=0, pos_label=1.0)\n",
        "try:\n",
        "    auc = roc_auc_score(y_te01, scores_te)\n",
        "except Exception:\n",
        "    auc = float('nan')\n",
        "\n",
        "cm = confusion_matrix(y_te, y_pred, labels=[-1.0, 1.0])\n",
        "\n",
        "print(\"==== TEST METRICS ====\")\n",
        "print(f\"Threshold used   : {best_th:.6f}\")\n",
        "print(f\"Accuracy         : {acc:.4f}\")\n",
        "print(f\"Balanced Acc     : {bacc:.4f}\")\n",
        "print(f\"Precision/Recall/F1: {prec:.4f}/ {rec:.4f}/ {f1:.4f}\")\n",
        "print(f\"ROC-AUC          : {auc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "collapsed_sections": [
        "AbjthIb7rvuS",
        "OuwBH3N8rojA"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}